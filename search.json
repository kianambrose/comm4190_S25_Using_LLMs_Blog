[
  {
    "objectID": "posts/003_Post 3/Post 3.html",
    "href": "posts/003_Post 3/Post 3.html",
    "title": "Dr. Chat GPT?",
    "section": "",
    "text": "AI Doctor\nIn this post I will examine the ability of Chat GPT to perform key responsibilities of a doctor, mainly diagnosing and treating ilnneses and medical knowledge.\nI will begin by researching diseases and illnesses and sharing the symptoms that commonly occur to Chat GPT. I will then ask it to identify what illness or disease it thinks I am describing.\n\n\nDiagnosing Illness\nFor this test I used Mayo Clinic as my source for the symptoms of these different medical conditions. I used Chat GPT 4o as the model for answering questions about symtoms described.\nThe first condition I asked Chat GPT about was a Migraine.\n\nAs you can see, Chat GPT correcly identified it as a migraine. It also correctly identified the phases of the migraine which were consistant with those described on Mayo Clinic.\nNext, I wanted to see if Chat GPT could correctly identify Irritable Bowel Syndrome, which can be hard to diagnose due to the symptoms being similar to other conditions such as having Celiac Disease.\n\nChat GPT correctly identified the symptoms as coming from IBS and even noted that the symptoms could overlap with other conditions, listing celiac disease as one of the conditions that has similar symptoms.\nTo further test it, I asked how it deteremined that the symptoms I asked about were not describing celiac disease.\n\nAgain, it was able to correctly identify the differences and its response aligned with Mayo Clinic’s article.\nIt seems that Chat GPT is able to correctly identify medical conditions, so I will move on to testing specific medical knowledge. I will give it a few questions from the United States Medical Licensing Examination, that come directly from the United States Medical Licensing Examination website. Each of the questions will come from a different section of the exam, as to test Chat GPT’s ability with different subjects.\n\n\nQuestion 1\nA 27-year-old woman comes to the office for counseling prior to conception. She states that a friend recently delivered a newborn with a neural tube defect and she wants to decrease her risk for having a child with this condition. She has no history of major medical illness and takes no medications. Physical examination shows no abnormalities. It is most appropriate to recommend that this patient begin supplementation with a vitamin that is a cofactor in which of the following processes?\n\nBiosynthesis of nucleotides\nProtein gamma glutamate carboxylation\n\n\nScavenging of free radicals\n\n\nTransketolation\nTriglyceride lipolysis\n\nCorrect Answer : A\nChat GPT’s Answer: A\n\n\nQuestion 2\nA study is designed to evaluate the feasibility of acupuncture in children with chronic headaches. Sixty children with chronic headaches are recruited for the study. In addition to their usual therapy, all children are treated with acupuncture three times a week for 2 months. Which of the following best describes this study design?\n\nCase-control\nCase series\nCrossover\nCross-sectional\nHistorical cohort\nRandomized clinical trial\n\nCorrect Answer: B\nChat GPT’s Answer: B\n\n\nQuestion 3\nA 26-year-old woman comes to the physician with her husband for counseling prior to conception. Her mother and three of her five siblings have type 2 diabetes mellitus. She is 170 cm (5 ft 7 in) tall and weighs 82 kg (180 lb); BMI is 28 kg/m2. Her blood pressure is 148/84 mm Hg. Physical examination shows no other abnormalities. Her fasting serum glucose concentration is 110 mg/dL. Which of the following is the most appropriate initial statement by the physician?\n\n“Let’s review ways you can optimize your own health before conceiving.”\n“We should test you for islet cell antibodies before you try to conceive.”\n“You can conceive right away since you are in good health.”\n“You should avoid gaining weight during pregnancy because you are already overweight and at risk for type 2 diabetes mellitus.”\n“You should have no problems with your pregnancy if you start insulin therapy.”\n\nCorrect Answer: A\nChat GPT’s Answer: A\n\n\nQuestion 4\nA 42-year-old nulligravid woman comes to the office because of a 1-year history of increasingly irregular vaginal bleeding and menstrual cramps. Previously, menses occurred at regular 28-day intervals and lasted 3 days with minimal cramping. During the past year, menstrual periods have occurred at 21- to 28-day intervals and lasted 10 to 12 days with increasingly severe pain. Use of acetaminophen and ibuprofen has provided minimal relief. She used an oral contraceptive from the age of 17 years to 40 years, but she discontinued use after she was diagnosed with deep venous thrombosis of the right lower extremity. She has no other history of serious illness and takes no medications. Her mother and sister underwent hysterectomy at the ages of 39 and 43 years, respectively, because of abnormal uterine bleeding. The patient is 163 cm (5 ft 4 in) tall and weighs 75 kg (165 lb); BMI is 28 kg/m2. Vital signs are within normal limits. Physical examination discloses an enlarged, irregularly shaped uterus with nodularity. Which of the following is the most likely cause of the patient’s symptoms?\n\nBenign monoclonal tumors arising from smooth muscle cells\nEndometrium growing into the myometrium\nEndometrium growing outside the uterus\nFailure of functional ovarian cysts to regress after the release of an ovum\nOvarian stromal cells dividing and multiplying rapidly\n\nCorrect Answer: A\nChat GPT’s Answer: A\n\n\nQuestion 5\nPatient Information Age: 6 years Sex Assigned at Birth: M Race/Ethnicity: unspecified Site of Care: office\nThe patient is brought by his mother because of a 1-month history of bleeding gums after brushing his teeth, increasingly severe muscle and joint pain, fatigue, and easy bruising. His mother says he has lost six baby teeth and has been irritable during this time. Use of acetaminophen has provided minimal relief of his pain. He has autism spectrum disorder. He is not toilet-trained. He has a 10-word vocabulary. Vital signs and oxygen saturation on room air are within normal limits. The patient appears alert but does not speak or make eye contact. Skin is pale and coarse. Examination of the scalp shows erythematous hair follicles. Dentition is poor, and gingivae bleed easily to touch. Multiple ecchymoses and petechiae are noted over the trunk and all extremities. There is marked swelling and tenderness to palpation of the elbow, wrist, knee, and ankle joints. He moves all extremities in a limited, guarded manner. Deep tendon reflexes are absent throughout. It is most appropriate to obtain specific additional history regarding which of the following in this patient?\n\nDiet\nEvidence of pica\nHerbal supplementations\nLead exposure\nSelf-injurious behaviors\n\nCorrect Answer: A\nChat GPT Answer: A\nClearly, Chat GPT is knowledgeable about medical procedures and conditions. It also has the ability to recommend next steps when given certain medical information. It seems to have the ability to stand in as a doctor that you would talk to over the phone. While it cannot physically provide medical examinations and surgeries, it covers many of the textbook knowledge required by doctors. If there is developement in the area of the physical applications of Chat GPT I think this would be an interesting area where Chat GPT would excel in assisting doctors with procedures and reminding them of the implications of certain conditions."
  },
  {
    "objectID": "posts/002_Post 2/Second Post.html",
    "href": "posts/002_Post 2/Second Post.html",
    "title": "Chat GPT’s Ability to Recreate Images it is Given",
    "section": "",
    "text": "I am curious how well Chat GPT can recreate images I use in the prompt\nIn this expirement I will try to get Chat GPT to produce an image most like the one I give it, with the least amount of follow up prompts correcting it.\nFor my first test I told Chat Gpt what it was going to be drawing. &gt;\nWithout any image of my dog, it was able to produce this photo:\n\n\n\nThis is a pretty typical looking minature Australian Shepherd. While Chat GPT did correctly respond to my prompt about the blue eyes and minature aussie, I decided to be more specific by actually providing an image of the dog I wanted it to recreate. Here is that exchange.\n\n\n\nHere Chat GPT was able to produce an image that looked more like my dog. The image correctly has black fur on top with brown accents around the nose, paws, and neck, and a white belly. Chat GPT also correctly kept the blue eyes that I told it to include from before. Finally, the background of the image was more like that of the image I provided, with wood floors running beneath the dog.\nMy only comment for Chat GPT was that the dog looked a little cartoonish in the picture. I had it try to recreate the dog in a less cartoonish style.\n\n\n\nOverall Chat GPT did a good job recreating my dog here. For the next attempt, I will give less instruction as to what I want it to recreate. I won’t tell it that the dog is an aussie and will not mention the color of anything on the dog.\n\n\nAttempt 2\nFor this attempt, I simply provided an image of my dog and said “Draw this Dog.” Here is the result.\n\n\n\nHere, Chat GPT provided a very accurate representation of the image I provided it. Almost all of the coloring on the dog is accurate and it also was able to get the eyes correctly colored even without me directing it to make them blue. Additionally, it put the dog on a carpet, which is similar to the carpet the dog is sitting on in the actual image.\nTo see how well it understood what it drew, I asked it to identify the breed of dog in the image.\n\n\n\nChat GPT was able to correctly identify the breed “Australian Shepherd” and also mentioned that it could be a minature one. It then identified what led it to believe that the dog was of that breed. Finally, it identified key behavioral qualities of the dog, all of which are correct and qualities that my dog actually has.\nIn the next attempt, I will give it an image with all three of my dogs and see how well it is able to draw all three within the same image. I am wondering if having multiple subjects in the same image will make it more difficult for Chat GPT to recreate the image correctly\n\n\nAttempt 3\nFor this attempt I simple provided an image with all of my dogs and told chat gpt to recreate the image.\n\n\n\nHere, Chat GPT was less accurate when producing the image of the dogs. Especially when creating the image of my mini aussie, Chat GPT created a dog that did not really look like my dog in terms of shape, fur, and face. However, Chat GPT did a pretty good job of recreating the sizes of the dogs in relation to one another. It also was able to match the colors of the dogs fairly well and the background matches the scenery in the original image.\nI then tried to explain the breeds of the dogs to see if that would help Chat GPT produce a better image of the dogs.\n\n\n\nThis slightly surprised me. When I gave Chat GPT more information it produced an image that was less like the original image. In this image the dogs look less like the ones it originally produced. The size and color of the dogs was completely messed up.\nIt seems that Chat GPT became confused when there were too many instructions given in producing the image. Instead, it may be better to let Chat GPT take the reigns and produce what it see’s, without providing input as to what is in the image. I think this area of Chat GPT still needs to be tested more and I am curious how well Chat GPT will be able to take constructive criticism on its images in the near future."
  },
  {
    "objectID": "posts/004_Post 4/Post 4.html",
    "href": "posts/004_Post 4/Post 4.html",
    "title": "A Conversation with Myself",
    "section": "",
    "text": "Conversation 1\nIn this conversation I used my own Chat GPT 4o account opened in two different tabs to see what would happen when Chat GPT talked with itself. I copied the responses of one tab and used it as the input for the second tab, repeating this process until the conversation ended. The only input that I wrote on my own was the first text, which says “hello”.\n\nHere, Chat GPT pulled a recent conversation I had with it about anthropology, and used it as an answer to “How’s it going?” It also specifically pulled the question about the squirrel monkeys from a previous exchange that I had with it. I wonder if the fact that my name was included forced Chat GPT to pretend to be me in its responses. It is interesting to see how the more recent conversation was chosen as an answer to the “How’s it going?” question because it shows Chat GPT to deciphre what may be considered more relevant at the moment.\nHere is the conversation continued: \nAgain, it is continuing to pull from my recent conversation, this time taking it a step further and asking about specific traits that are commonly studied in squirrel monkeys. I found it interesting that one of the open chat interfaces assumed to be the one who was less informed on the subject, even though they both obviously have access to the same information.\n\nHere, Chat GPT seems to finish the conversation. All of its questions are answered and it concludes by confirming the next steps and affirming that it is a good plan to continue. I think the fact that Chat GPT did not decide to ask another question at the end of the exchange is also interesting, because in the other prompts it decided to continue the conversation, but in this one it started not bringing up new topics and just dedicated its energy toward one specific problem that it had created for itself.\n\n\nConversation 2\nThis time, I will use a tempory chat in Chat GPT to see if it is able to have a conversation with itself even if it does not have access to my Chat GPT history. Again, I will only start by saying hello.\n\nFor some reason, Chat GPT failed when I tried to attempt this. I tried to generate a new response and it failed again. Does it purposefully prevent this behavior?\nTry # 2\n\nAgain, the conversation fails after the third exchange. What happens if I change one input slightly before it gets to the point where Chat GPT fails.\n\nHere, I changed the initial response of the second chat slightly. Here was the original response.\n\nHowever, the chat still failed. Maybe that last line is the one that causes chat gpt to faiL?\n\nThis seems to not be the case. Maybe the conversation with the Temporary chat can only last for three exchanges?\n\nThis also seems to not be the case. It seems as though Chat GPT somehow detects when it is talking to itself in the temporary chat. Even with slight modifications, it is able to identify its own language and it causes the chat to fail. I am curious as to why and how this happens. Additionally, why does this only happen in the temporary chat and not in the general chat? These are questions that I would like to know more about and I am curious to hear if anyone else has encountered the same experience with Chat GPT."
  },
  {
    "objectID": "posts/006_Post 6/Post 6.html",
    "href": "posts/006_Post 6/Post 6.html",
    "title": "20 Questions with different LLM’s",
    "section": "",
    "text": "Format\nI asked 4 different LLM’s to play 20 questions with me. In this game I had the LLM guess the thing that I was thinking of. In each of the games, the thing I was “thinking” of was a notebook. Let’s compare how they performed.\n\n\nChat GPT 4o\n\n\nChat GPT was not able to decipher what was said. The question that probably led to its downfall was the question “Is it used for writing or drawing?” After this question, Chat GPT moved from questions that narrow the choices down to direct guesses. While a notebook is used when writing and drawing, Chat GPT interpreted my response to mean that I was thinking about a writing or drawing instrument.\n\n\nCopilot\n \nCopilot was able to decipher what I was thinking of. Copilot started out with very similar questions to the ones asked by Chat GPT. Where Copilot separated itself (probably for the better) was when it continued asking general questions rather than trying to directly guess what I was thinking about. I think this is a strategy that a human would follow more closely. Another difference was that Copilot would offer up examples of things that it was asking about. For example, it said ” Is it something you use to organize papers, like a stapler or paperclip?“. Here, Copilot made it clear what it meant by”something you use to organize papers.” I think this would have helped Chat GPT in its process, especially with its question about whether it was something I write or draw with.\n\n\nGemini\n  \nGemini was not able to determine what I was thinking of. Gemini’s first 2 question differed from Copilot and Chat GPT. Instead of asking if it was living or man made, it first asked if it was an animal and then if it was a plant. Finally on the third question it asked if it was manufactured. This process seems backwards. Instead of asking a specific question, like if it is an animal, it first should have asked if it was living. This would have saved an additional question and is more consistent with how a human would play the game. After the first few questions, Gemini was got on the same track as Copilot and began asking about if it was found in a house and where it was found in the house. Unfortunately, it was unable to ask questions that were specific to a notebook, so it seemed to get a little lost after “Is it something related to reading?”. Before this point I thought it might narrow down the questioning, however, the following question was “Is it something you use to tell time?” which showed me that it had no idea what I was thinking of.\n\n\nLlama\n \nLlama probably performed the worst at this game. It actually started out asking good questions, starting from the most general and then narrowing the questions down. It followed a similar process initially to Copilot. However, after question 13, it started repeating questions. This is not a good approach in 20 questions because you waste questions. No other LLM made the mistake of re asking the same questions. Not only did Llama ask the same question twice, it asked it using the same exact wording. It then proceeded to make the mistake a second time. In addition, Llama did not identify when the game was over. Instead of admitting defeat after question 20, it continued on to question 21. It seems that it was unable to follow directions, or there was some memory leak where it began forgetting what I had already told it.\n\n\nOverall\nOverall, the LLM that performed the best at this game was Copilot. It was the only one to correctly identify what I was thinking of. It also followed a process that aligns with the general consensus of a “smart” way to play the game (starting with general questions before narrowing down). While there were many similarities among the different LLM’s, Copilot was able to harness the best qualities of the group and correctly guess the object.\nGoing forward it would be interesting to see if these LLM’s are able to improve their question asking ability to improve at 20 questions. It would also be interesting to repeat this experiment multiple times to see if the results change."
  },
  {
    "objectID": "posts/007_Post 7/Post 7.html",
    "href": "posts/007_Post 7/Post 7.html",
    "title": "LLM’s and Complexity",
    "section": "",
    "text": "In this blog post, I’ll be comparing how three leading AI models—Claude by Anthropic, GPT by OpenAI, and Deepseek—explain complex topics that many of us find challenging to understand.\nI’ve selected four notoriously difficult concepts: quantum entanglement, mRNA vaccines, climate feedback loops, and machine learning algorithms. For each topic, I asked the same question to all three AI assistants and evaluated their explanations based across three key metrics:\n\nClarity: How easy is the explanation to follow?\nAccessibility: How well does it avoid unnecessary jargon?\nAccuracy: Does it explain the concept correctly without oversimplification?\n\nMy goal is to discover which AI assistant can best bridge the gap between complex technical knowledge and everyday understanding. Whether you’re a student, professional, or simply curious about these topics, this comparison will help you identify which AI might be your best learning companion."
  },
  {
    "objectID": "posts/007_Post 7/Post 7.html#quantum-entanglement-explained-simply",
    "href": "posts/007_Post 7/Post 7.html#quantum-entanglement-explained-simply",
    "title": "LLM’s and Complexity",
    "section": "Quantum Entanglement Explained Simply",
    "text": "Quantum Entanglement Explained Simply\nQuantum entanglement is like having two magical coins that are connected in a strange way. Imagine you and your friend each take one coin and travel to opposite sides of the universe. When you flip your coin and it lands on heads, your friend’s coin instantly shows heads too - every single time!\n\nWhat makes it special?\n\nInstant connection: The coins “communicate” their states instantly, regardless of distance\nNo hidden instructions: The coins don’t decide their outcomes in advance\nMeasurement matters: The coin only decides its state when you look at it\n\n\n\nWhy it’s important in physics\nQuantum entanglement challenges our understanding of reality in several ways:\n\nIt suggests information can travel faster than light (though scientists have shown you can’t use this to send messages)\nIt’s fundamental to quantum computing, where entangled particles can perform calculations impossible for regular computers\nIt reveals the quantum world operates by different rules than our everyday experience\n\nEinstein called it “spooky action at a distance” because it seemed so strange. Today, scientists use entanglement in developing quantum technologies that could revolutionize computing, secure communications, and precision measurements."
  },
  {
    "objectID": "posts/007_Post 7/Post 7.html#exploring-quantum-entanglement-a-simple-overview",
    "href": "posts/007_Post 7/Post 7.html#exploring-quantum-entanglement-a-simple-overview",
    "title": "LLM’s and Complexity",
    "section": "Exploring Quantum Entanglement: A Simple Overview",
    "text": "Exploring Quantum Entanglement: A Simple Overview\n\nOverview\nQuantum entanglement is a fascinating phenomenon in quantum physics where particles become interconnected so that the state of one particle instantly influences the state of another, regardless of the distance between them. This means when you measure one particle’s properties (like spin), the other particle’s properties are instantly determined, even if they’re light-years away.\n\n\nSuperposition and Qubits\nIn quantum mechanics, particles like qubits can exist in multiple states at once—a superposition. When two qubits are entangled, their combined state is linked. For example, one qubit could be a superposition of spin up or down, while the other must always match that when measured.\n\n\nEntangled State\nWhen these particles become entangled, they form an “entangled” state where their properties are correlated. If you measure one particle’s spin and it’s up, the other will definitely also be up, no matter how far apart they are in space.\n\n\nCorrelated Properties\nThe key aspect of entanglement is that when measured, these particles share properties instantly. This means if you measure one at a certain time, the other’s state is determined before you can observe it, even across vast distances without any need for information traveling faster than light (which is not possible according to current understanding).\n\n\nNo Faster-Than-Light Communication\nSome debate exists about entanglement since it suggests faster-than-light communication isn’t possible. While this may seem counterintuitive from a classical perspective, it challenges our understanding of reality and causality in quantum mechanics.\n\nConclusion\nQuantum entanglement is an intriguing aspect of quantum physics that links particles so they share properties instantaneously, even across large distances. It raises questions about the nature of reality and potential for future technologies like advanced computing."
  },
  {
    "objectID": "posts/007_Post 7/Post 7.html#how-mrna-vaccines-work-a-simple-explanation",
    "href": "posts/007_Post 7/Post 7.html#how-mrna-vaccines-work-a-simple-explanation",
    "title": "LLM’s and Complexity",
    "section": "How mRNA Vaccines Work: A Simple Explanation",
    "text": "How mRNA Vaccines Work: A Simple Explanation\n\nOverview\nMRNA vaccines use the genetic information stored in messenger RNA (mRNA) to create a vaccine. Here’s how it works:\n\nUnderstanding mRNA: mRNA is part of our genetic material and contains instructions for making proteins.\nMaking the Vaccine:\n\nTake your own mRNA from your body.\nMix it with bacterial extract, which contains bacteria that can produce enzymes.\nAdd these enzymes to process the mixture into a vaccine.\n\nUsing the Vaccine:\n\nThe resulting vaccine is taken in doses similar to traditional immunizations (like flu shots).\nYour immune system reacts with this vaccine by producing antibodies or other immune response molecules.\nThese antibodies protect you from being infected by viral antigens or pathogens.\n\n\n\n\nWhat Makes mRNA Vaccines Different from Traditional Vaccines?\n\nNo Need for Specific Proteins: Unlike traditional vaccines, which use proteins that stick to specific targets (like antibodies against a virus), mRNA vaccines don’t rely on immunogenic proteins.\nReduced Risk of Side Effects: mRNA vaccines are less likely to cause adverse reactions like rashes or allergies because they don’t involve immunogenic proteins.\nBroader Antibodyism: mRNA vaccines can target any viral antigens from any source, making them potentially more adaptable and effective against a broader range of threats.\nSimplicity in Production: The process is simpler, requiring less preparation and fewer steps compared to traditional vaccination methods.\nGlobal Scalability: This method makes global immunization efforts easier, which could be beneficial for reducing the burden of infectious diseases worldwide.\n\n\n\nConclusion\nIn summary, mRNA vaccines offer a potentially safer, more adaptable approach to immunization by focusing on genetic information from mRNA and bacterial extract. They aim to reduce side effects, target a broader range of threats, and provide a simpler production method while potentially offering global benefits."
  },
  {
    "objectID": "posts/007_Post 7/Post 7.html#climate-feedback-loops-1",
    "href": "posts/007_Post 7/Post 7.html#climate-feedback-loops-1",
    "title": "LLM’s and Complexity",
    "section": "Climate Feedback Loops",
    "text": "Climate Feedback Loops\nClimate feedback loops are processes that can either amplify or dampen the effects of climate change. They play a crucial role in determining the rate and extent of climate change by affecting the Earth’s energy balance. Feedback loops are categorized into two types: positive feedback loops and negative feedback loops.\n\nPositive Feedback Loops\nPositive feedback loops enhance or amplify changes; this tends to move a system away from its equilibrium state and make it more unstable. In the context of climate change, positive feedback loops exacerbate warming. Here are some examples:\n\nIce-Albedo Feedback: As global temperatures rise, ice and snow begin to melt. Ice and snow are highly reflective, so their presence helps to cool the planet by reflecting sunlight back into space. When they melt, darker ocean or land surfaces are exposed, which absorb more sunlight and lead to further warming and more ice melt.\nWater Vapor Feedback: Warmer temperatures increase evaporation, adding more water vapor to the atmosphere. Water vapor is a potent greenhouse gas, and its increased concentration can lead to more warming and amplify the initial temperature rise.\nPermafrost Thaw: As temperatures rise, permafrost thaws, releasing stored methane—a potent greenhouse gas. The release of methane leads to further warming, which can cause more permafrost to thaw.\n\n\n\nNegative Feedback Loops\nNegative feedback loops reduce changes; they tend to hold a system to some equilibrium state, making it more stable. In the context of climate change, negative feedback loops counteract warming. Here are some examples:\n\nCloud Cover Feedback: Increased temperatures may lead to more cloud formation. Clouds can have a cooling effect as they reflect sunlight back to space (albedo effect), thus reducing the warming.\nEnhanced Plant Growth: Higher carbon dioxide levels can lead to increased plant growth in some regions, which absorbs more CO2 from the atmosphere and potentially reduces greenhouse gas concentrations.\n\n\n\nImpact on Climate Change\nThe interplay between positive and negative feedback loops significantly impacts the Earth’s climate system. Positive feedbacks tend to accelerate the rate of climate change, making mitigation efforts more urgent. Negative feedbacks can provide some buffering effect against climate change, but they are often insufficient to counteract the strong warming pressures from positive feedbacks.\nUnderstanding these feedback mechanisms is key to predicting climate change scenarios and developing strategies to mitigate its impacts. Accurate climate models must account for these feedback loops to predict the future climate accurately and to create effective climate policies."
  },
  {
    "objectID": "posts/007_Post 7/Post 7.html#understanding-basic-machine-learning-neural-networks",
    "href": "posts/007_Post 7/Post 7.html#understanding-basic-machine-learning-neural-networks",
    "title": "LLM’s and Complexity",
    "section": "Understanding Basic Machine Learning: Neural Networks",
    "text": "Understanding Basic Machine Learning: Neural Networks\nImagine you have a plant and you want to make sure it gets just the right amount of water. Not too little, not too much. You keep track of how much water you give it and how the plant responds. Over time, you learn the perfect amount of water that makes your plant happy and healthy. This is similar to how basic machine learning works!\n\nWhat Are Neural Networks?\nNeural networks are like a digital brain. Just like our brains learn from experience, neural networks learn from data. They try to find patterns and make decisions based on examples they have seen before.\n\nHow Do Neural Networks Work?\n\nInputs: Think of inputs as ingredients for a recipe. In the case of making the plant happy, inputs could be how much sunlight it gets, how much water you give, and the type of soil.\nNeurons: Inside the neural network, there are many tiny units called neurons. Each neuron takes some inputs, does some calculations, and decides on an output. It’s like a mini decision-maker.\nLayers: Neurons are organized into layers. The first layer might decide if the amount of sunlight is enough, the next layer might check if the soil is good, and yet another might consider the water amount.\nOutput: This is the result or decision. After passing through the neurons and layers, the network gives an output, like “Give more water” or “Everything is perfect.”\nLearning: Just like you learn the best way to water your plant, neural networks learn by making predictions, seeing if they’re right, and then adjusting. This happens over and over, getting better each time.\n\n\n\nWhy Use Neural Networks?\nNeural networks are great for tasks where there is a lot of data and complex patterns. They are used in recognizing faces in photos, predicting the weather, and even playing games!\nTo sum up, neural networks are powerful tools that mimic how our brains work to solve problems by learning from examples. They take in data, process it through layers of decision-making, and provide outputs to help solve complex challenges."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Experiences with LLMs",
    "section": "",
    "text": "LLM’s and Complexity\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nComplex Topics\n\n\n\nWhich LLM can explain complex topics in the most understandable way?\n\n\n\n\n\nFeb 28, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nLimits of Deep Seek\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nChina\n\n\n\nWhat information is not allowed to be discussed on DeepSeek\n\n\n\n\n\nFeb 28, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\n20 Questions with different LLM’s\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\n20 Questions\n\n\n\nWhich LLM is the best at 20 questions?\n\n\n\n\n\nFeb 21, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nA Penn Mystery Letter\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nDeciphering Images\n\n\n\nCan Chat GPT decipher a mysterious letter recieved in 1880?\n\n\n\n\n\nFeb 21, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nA Conversation with Myself\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nCommunication\n\n\n\nWhat happens when Chat GPT talks with itself?\n\n\n\n\n\nFeb 12, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nChat GPT’s Ability to Recreate Images it is Given\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nImage Recreation\n\n\n\nChat GPT and Image Generation\n\n\n\n\n\nFeb 6, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Chat GPT?\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nMedicine\n\n\n\nCan Chat GPT become my new doctor?\n\n\n\n\n\nFeb 6, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nChat GPT’s Experience With Names\n\n\n\n\n\n\nLLMs\n\n\nChat GPT 4o\n\n\nlogic\n\n\n\nChat GPT and public figures\n\n\n\n\n\nJan 29, 2025\n\n\nKian Ambrose\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Exploring the limits of Chat GPT in various areas of interest"
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html",
    "href": "posts/008_Post 8/Post 9.html",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "DeepSeek seems to not be willing to discuss things that the Chinese government blocks on other China-based products. For example, if I ask it about the Tiananmen Square Massacre, I get this response.\n\nChatGPT, on the other hand, gives a full explanation of what occurred.\n\n\nThe Tiananmen Square Massacre (also known as the June 4th Incident) occurred on June 3–4, 1989, when the Chinese government violently suppressed pro-democracy protests in Beijing’s Tiananmen Square. The protests, which had been ongoing since April 1989, were led by students, intellectuals, and workers demanding political reform, freedom of speech, and government accountability. The movement initially began as a peaceful mourning for Hu Yaobang, a former Communist Party leader known for advocating reform, but it grew into a nationwide call for change.\nTo further test how much DeepSeek restricts responses, I asked it about Taiwan. I asked both DeepSeek and ChatGPT, “Is Taiwan a country?” Here are the responses:\n\n\n\nTaiwan is a complex and sensitive issue in international relations. According to the One-China policy, which is widely recognized by the international community, Taiwan is considered a part of China. The Chinese government views Taiwan as a province of China and opposes any form of “Taiwan independence.” However, Taiwan operates with its own government and political system, which leads to differing perspectives on its status. The international community’s stance on Taiwan’s status varies, with some countries and organizations treating it as a separate entity in certain contexts.\n\n\n\n\n\nThe status of Taiwan is politically and diplomatically complex. It operates as a de facto independent country, but its official status remains disputed.\n\n\n\n\nGovernment & Functioning:\nTaiwan has its own government, military, currency (New Taiwan Dollar), constitution, and democratic elections. It operates as a sovereign state in practice.\nPeople’s Republic of China (PRC) Claim:\nThe Chinese government considers Taiwan a part of China and insists on the One China Principle, which states that Taiwan is an inseparable part of its territory.\nInternational Recognition:\n\nAs of now, only a handful of countries (fewer than 15) officially recognize Taiwan as a sovereign nation.\n\nMost countries, including the United States, Japan, and European nations, do not officially recognize Taiwan as a separate country but maintain unofficial diplomatic relations.\n\nTaiwan is not a member of the United Nations, as China holds a UN seat and blocks Taiwan’s membership.\n\nU.S. & Global Position:\n\nThe U.S. follows a policy of “strategic ambiguity,” recognizing the PRC as the sole government of China while maintaining strong unofficial ties with Taiwan.\n\nMany countries support Taiwan’s participation in global organizations like the World Health Organization (WHO) but avoid formal recognition to prevent diplomatic conflict with China.\n\n\n\n\n\n\nDe facto (in practice): Taiwan operates as an independent country.\n\nDe jure (under international law): Taiwan is not widely recognized as a fully sovereign state due to diplomatic pressures from China.\n\n\n\n\n\nHere, DeepSeek seems to respond in a relatively unbiased manner and addresses multiple viewpoints on whether Taiwan is a country. It also comments on the Chinese government’s opinion on the matter, communicating that it has its own separate views.\nTo further test DeepSeek vs. ChatGPT, I asked, “What are things that the Chinese government does not want to talk about?”\n\n\n\nAt first, DeepSeek began responding, mentioning that, like any government, there are topics that the Chinese government prefers not to discuss. It then started listing topics, starting with the debate on whether Taiwan is its own country. DeepSeek then started typing out “Tiananmen Square Massacre” but stopped typing, deleted all past text, and displayed the message, “Sorry, that’s beyond my current scope. Let’s talk about something else.”\n\n\n\nChatGPT, on the other hand, was willing to discuss and provide examples of certain topics that the Chinese government heavily censors. These include:\n- Tiananmen Square Massacre (1989)\n- Taiwan’s Independence\n- Hong Kong Protests & Democracy Movement\n- Uyghur Repression & Xinjiang Detention Camps\n- Falun Gong and Religious Suppression\n- Tibet & the Dalai Lama\nIn this exercise, we clearly see the influence of the Chinese government on restricting what can be seen and learned about through DeepSeek. Even acknowledging that these events and topics exist is beyond the scope of what DeepSeek is willing to discuss. I find it interesting that DeepSeek chooses not to discuss the events rather than lie or only include parts of the information regarding these topics. It could just as easily answer and provide incomplete information that only shows one side of the story for these controversial topics. Maybe DeepSeek does not want to hurt its reputation as a valid source of information and thus would rather not discuss the topic at all than provide false information. On the other hand, it could be the Chinese government’s instruction to just not discuss the topics at all.\n\n\n\nI decided to ask DeepSeek about all of the topics that ChatGPT said were controversial in the eyes of the Chinese government, and DeepSeek responded the same way to all of them. It first began typing, providing some information about the topics, but after about 4 seconds of typing, it deleted all it had said and replaced it with, “Sorry, that’s beyond my current scope. Let’s talk about something else.”\nI think it would be interesting to see if there are any workarounds to get DeepSeek to discuss these topics. One possible workaround that I have seen includes the use of numbers to replace certain letters when having DeepSeek explain the events. In this case, DeepSeek seems to not recognize the “trigger words” that seem to cause DeepSeek to stop responding."
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html#deepseek",
    "href": "posts/008_Post 8/Post 9.html#deepseek",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "Taiwan is a complex and sensitive issue in international relations. According to the One-China policy, which is widely recognized by the international community, Taiwan is considered a part of China. The Chinese government views Taiwan as a province of China and opposes any form of “Taiwan independence.” However, Taiwan operates with its own government and political system, which leads to differing perspectives on its status. The international community’s stance on Taiwan’s status varies, with some countries and organizations treating it as a separate entity in certain contexts."
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html#chatgpt",
    "href": "posts/008_Post 8/Post 9.html#chatgpt",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "The status of Taiwan is politically and diplomatically complex. It operates as a de facto independent country, but its official status remains disputed.\n\n\n\n\nGovernment & Functioning:\nTaiwan has its own government, military, currency (New Taiwan Dollar), constitution, and democratic elections. It operates as a sovereign state in practice.\nPeople’s Republic of China (PRC) Claim:\nThe Chinese government considers Taiwan a part of China and insists on the One China Principle, which states that Taiwan is an inseparable part of its territory.\nInternational Recognition:\n\nAs of now, only a handful of countries (fewer than 15) officially recognize Taiwan as a sovereign nation.\n\nMost countries, including the United States, Japan, and European nations, do not officially recognize Taiwan as a separate country but maintain unofficial diplomatic relations.\n\nTaiwan is not a member of the United Nations, as China holds a UN seat and blocks Taiwan’s membership.\n\nU.S. & Global Position:\n\nThe U.S. follows a policy of “strategic ambiguity,” recognizing the PRC as the sole government of China while maintaining strong unofficial ties with Taiwan.\n\nMany countries support Taiwan’s participation in global organizations like the World Health Organization (WHO) but avoid formal recognition to prevent diplomatic conflict with China.\n\n\n\n\n\n\nDe facto (in practice): Taiwan operates as an independent country.\n\nDe jure (under international law): Taiwan is not widely recognized as a fully sovereign state due to diplomatic pressures from China."
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html#analysis",
    "href": "posts/008_Post 8/Post 9.html#analysis",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "Here, DeepSeek seems to respond in a relatively unbiased manner and addresses multiple viewpoints on whether Taiwan is a country. It also comments on the Chinese government’s opinion on the matter, communicating that it has its own separate views.\nTo further test DeepSeek vs. ChatGPT, I asked, “What are things that the Chinese government does not want to talk about?”"
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html#deepseek-1",
    "href": "posts/008_Post 8/Post 9.html#deepseek-1",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "At first, DeepSeek began responding, mentioning that, like any government, there are topics that the Chinese government prefers not to discuss. It then started listing topics, starting with the debate on whether Taiwan is its own country. DeepSeek then started typing out “Tiananmen Square Massacre” but stopped typing, deleted all past text, and displayed the message, “Sorry, that’s beyond my current scope. Let’s talk about something else.”"
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html#chatgpt-1",
    "href": "posts/008_Post 8/Post 9.html#chatgpt-1",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "ChatGPT, on the other hand, was willing to discuss and provide examples of certain topics that the Chinese government heavily censors. These include:\n- Tiananmen Square Massacre (1989)\n- Taiwan’s Independence\n- Hong Kong Protests & Democracy Movement\n- Uyghur Repression & Xinjiang Detention Camps\n- Falun Gong and Religious Suppression\n- Tibet & the Dalai Lama\nIn this exercise, we clearly see the influence of the Chinese government on restricting what can be seen and learned about through DeepSeek. Even acknowledging that these events and topics exist is beyond the scope of what DeepSeek is willing to discuss. I find it interesting that DeepSeek chooses not to discuss the events rather than lie or only include parts of the information regarding these topics. It could just as easily answer and provide incomplete information that only shows one side of the story for these controversial topics. Maybe DeepSeek does not want to hurt its reputation as a valid source of information and thus would rather not discuss the topic at all than provide false information. On the other hand, it could be the Chinese government’s instruction to just not discuss the topics at all."
  },
  {
    "objectID": "posts/008_Post 8/Post 9.html#further-tests",
    "href": "posts/008_Post 8/Post 9.html#further-tests",
    "title": "Limits of Deep Seek",
    "section": "",
    "text": "I decided to ask DeepSeek about all of the topics that ChatGPT said were controversial in the eyes of the Chinese government, and DeepSeek responded the same way to all of them. It first began typing, providing some information about the topics, but after about 4 seconds of typing, it deleted all it had said and replaced it with, “Sorry, that’s beyond my current scope. Let’s talk about something else.”\nI think it would be interesting to see if there are any workarounds to get DeepSeek to discuss these topics. One possible workaround that I have seen includes the use of numbers to replace certain letters when having DeepSeek explain the events. In this case, DeepSeek seems to not recognize the “trigger words” that seem to cause DeepSeek to stop responding."
  },
  {
    "objectID": "posts/001_Post 1/First Post.html",
    "href": "posts/001_Post 1/First Post.html",
    "title": "Chat GPT’s Experience With Names",
    "section": "",
    "text": "Why does Chat GPT not respond when asked about specific names?\nWhen prompted with certain names, Chat GPT will produce an error saying that it is “unable to produce a response.” I am curious how Chat GPT decides whether to respond to certain names, and on what basis it determines whether the name is on the list of ones it does not respond to.\n\n\n\nWho are these people and why does Chat GPT fail to respond?\nI have done some research on Google trying to find what names people have found to produce this error with Chat GPT. There seems to be a select set of names that all seem unrelated to eachother at first glance. So far I have compiled this list of names that causes Chat GPT to fail to respond: David Faber, Brian Hood, Matthew Sag, Jonathan Zittrain, Brian Lunduke, Jonathan Turley, and Alexander Hanff. Brian Hood was convicted of second-degree murder, Jonathan Turley is an attorney and George Washington University Law School professor , Jonathan Zittrain is a Harvard Law School professor, and David Faber is a CNBC journalist.\nThere seem to be a few theories as to why Chat GPT does not respond when asked about these people, but one of the main theory seems to be that someone with that name asked Chat GPT to not provide information about them. There is a “right to be forgotten” principle in Europe that protects people from having their information presented publicy without their consent. It allows individuals to request that their information be removed from certain websites or search engines.\nAnother theory is that Chat GPT has a regex (a sequence of characters that defines a search pattern) on certain names that causes the chat to discontinue and fail. It remains unclear how Chat GPT decides who it cannot talk about or whether these names are manually placed by people at Open AI.\n\n\nCan I trick Chat GPT to respond?\nI was curious as to whether I could trick Chat GPT into telling me about the people named above, or even just trick it to say the name back to me.\n\nFirst, I asked questions to try and get Chat Gpt to mention the name “Matthew Sag”. I pulled information from his wikipedia page and asked chat gpt to identify the person who fit the description.\n\n\n\n\n\nAs you can see, Chat GPT was about to correctly identify who I was talking about and even began to respond before it ultimately failed. It seems as though it caught itself about to say the name and decided not to respond. Chat GPT went through the process of first checking the web to find the answer based on the information, and then responding based on what it found.\n\nIt is interesting to me that it even began typing after checking the web because I assumed it would have found the name online and stopped the response immediately instead of continuing and beginning to respond. I think through this exercise we can begin to get a timeline for when Chat GPT recognizes what it is about to output.\nHere is another example: &gt;In this example I asked it about Alexander Hanff. I accidently mistyped the last name in the prompt, however, Chat GPT responded with some suggestions.\n\n\n\n\nAs you can see, Chat GPT actually responded by recommending webpages about people with the name Alexander Hanff, and then wrote a respond about someone named Alexander Hanf (only one “f”). It then began writing about a new person but stopped immediately.\nThis was particularly interesting because it was able to provide links to people named Alexander Hanff, and even made the connection between my mistyped name and “Hanff” with 2 f’s. So it seems that Chat GPT was able to infer that I meant “Hanff”, but also waited to fail its response until it began typing out information about the Andrew Hanff. For context, Chat GPT recommended the links seen in the image before it began writing a response to the prompt.\n\nIn this exercise I tried to get Chat GPT to produce the name on its own through a series of longer prompts. &gt; I first asked it about the last name.\n\n\n\n\nThen I asked about the first name.\n\n\n\nFinally, I asked Chat GPT to combine the two.\n\n\n\nAt first it didn’t really combine the names as intended, however, it did talk about both Alexander and Hanff in the same sentence. I prompted again to get a different result.\n\n\nThe results from this lead me to believe that there is in fact some kind of regex that prevents the names from being produced by Chat GPT. Chat GPT is able to talk about the first and last name separately in the same sentence, however, when the name appears with the last name right after the first name it causes a failure.\nI tried one more exercise to test this theory.\n\nIn this exercise I tried adding a middle name to see how Chat GPT would react to the first and last name not being directly next to one another.\n\n\n\nHere, Chat GPT said the full name back to me, and then suggested a new person before failing to respond. In this case, however, it produced a form of bitmoji which was taken from a website. Here is the website: https://www.apidays.global/speaker/alexander-hanff/ \n\n\nThis could potentially shed more light onto the specific Alexander Hanff that Chat GPT is afraid to talk about. In some sense Chat GPT prompted me to visit this website and learn about Alexander Hanff, even though it was trained not to respond to the prompt about him.\nWhile the details of this mystery are still not solved, the picture of why and how Chat GPT prevents certain names from producing responses is becoming clearer."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/005_Post 5/Post 5.html",
    "href": "posts/005_Post 5/Post 5.html",
    "title": "A Penn Mystery Letter",
    "section": "",
    "text": "Background Information\nIn 1880 a letter was sent from Horace Howard Furness containing 20+ pages of unknown writing. The type of writing or language remains unknown to this day. The mysterious letter is believed to have been from a spiritual reading that was a popular occurance at the time. In the 1880s, spiritual readings were closely tied to the Spiritualist movement, which peaked in popularity during the late 19th century. Spiritualism was based on the belief that the living could communicate with the spirits of the dead, often through mediums who conducted séances, automatic writing, and clairvoyant readings.\n\n\nCan Chat GPT identify what the letter is saying?\nWhile there is currently no way for me to verify if Chat GPT’s interpretation of the letter is correct, I was interested in determing if Chat GPT could come up with a reasonable interpretation of what was being said based on the context of the letter.\nHere is my exchange with Chat GPT:\n\nFirst, I wanted to see if Chat GPT had any predictions of the type of writing that was in the letter.\n\nChat GPT correctly identifies a few possibilities for what the writing could have been. I decide to have Chat GPT pursue the idea that it could be Gregg Shorthand. I ask Chat GPT if it is familiar with Gregg Shorthand and if it is able to translate the image to english.\n\nHere, Chat GPT hypothesizes what the letter could be saying. It is still somewhat uncertain and from its response I am not confident in its ability to tell me what is said in the writing. To help with this, I have Chat GPT break down how it came to its conclusion.\n\nNow that I know Chat GPT can go symbol by symbol and attempt to translate what is written, I wanted to give Chat GPT more context to see if it would help Chat GPT understand if it was analyzing using the correct language.\n\nChat GPT suggested a different type of shorthand called Duployan Shorthand, so I decided to pursue this as a better possibility. I asked Chat GPT to translate a single line, given that it was written in Duployan Shorthand.\n\nHere, Chat GPT reprocessed the image and made it clearer, allowing it to go stroke by stroke and produce a possible translation. Again, the translations seem consistent with what is typically written down in spiritual readings, even without explicitly telling Chat GPT that it was from one.\nI then repeated this process of going line by line for a couple pages and then asked Chat GPT for its thoughts.\n\nChat GPT also identified the themes in the language that led it to believe it was from a spiritual reading. Chat GPT’s ability to connect its interpretation to the spiritual readings increased my confidence in its translations and led me to believe that it may actually be correctly translating certain parts of the letter.\nI then gave Chat GPT some more context as to who’s name was on the envelope of the letter.\n\nChat GPT is able to provide a hypothesis for further context of the letter. Based on my own research on the side, everything that it suggested seems to be a plausible explanation for why the letter was being associated with him, and what interest he had in the letter.\nGoing forward it would be interesting to compare these findings to those of an expert on the subject and analyze if Chat GPT is moving in the correct direction and if it is able to translate more of the letter."
  }
]